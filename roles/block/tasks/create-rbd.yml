---

# https://www.ibm.com/docs/en/storage-ceph/7?topic=ccbduiflkmc-map-mount-ceph-block-device-linux-using-command-line
# https://du.cesnet.cz/en/navody/object_storage/cesnet_rbd/start
# https://docs.ceph.com/en/latest/rbd/rados-rbd-cmds/?highlight=orch%20device%20zap
# https://docs.e-infra.cz/storage/object-storage/rbd-setup/#rbd-configuration-and-its-mapping


- name: Initialize Pool for Rados Block Device
  shell: |
    rbd pool init {{ item.name }}
  register: init_rbd_pool
  with_items: "{{ _rbd.pool }}"
- debug: msg={{ init_rbd_pool }}
  when: print_debug == true


- name: Obtain I/O Information for a Specific Pool or All
  shell: |
    ceph osd pool stats {{ item.name }}
  register: rbd_pool_stats
  with_items: "{{ _rbd.pool }}"
- debug: msg={{ rbd_pool_stats }}
  when: print_debug == true


# when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
# until: obtain_pool_io.stdout.find("  nothing is going on") == 1
# retries: 50
# delay: 10
# ceph osd pool stats jtest_pool
# pool jtest_pool id 52
# nothing is going on


- name: Create Rados Block Device in Pool
  shell: |
    rbd create {{ item.name }} --size {{ item.size }} --pool {{ item.pool }}
  register: create_rbd_device
  with_items:
    - "{{ _rbd.image.default }}"
    - "{{ _rbd.image.cephfs }}"
    - "{{ _rbd.image.block }}"
    - "{{ _rbd.image.rgw }}"
    - "{{ _rbd.image.nfs }}"
- debug: msg={{ create_rbd_device }}
  when: print_debug == true


# Need to investigate why OSD id 0 got down
#- name: Purge OSD id 0
#  shell: |
#    ceph osd out osd.0
#    ceph osd purge 0 --yes-i-really-mean-it
#  register: purge_osd_zero

#- debug: msg={{ purge_osd_zero }}
#  when: print_debug == true


#- name: Disable and Delete Pool
#  shell: |
#    ceph osd pool delete tpool01 --yes-i-really-really-mean-it
#    ceph osd pool application disable tpool01 <app> {--yes-i-really-mean-it}
#  register: disable_ceph_pool
#
#- debug: msg={{ disable_ceph_pool }}

