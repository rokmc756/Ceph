# https://access.redhat.com/documentation/id-id/red_hat_ceph_storage/5/html/operations_guide/management-of-iscsi-gateway-using-the-ceph-orchestrator
# https://www.youtube.com/watch?v=bOPsVM43HOs
# https://documentation.suse.com/ses/7.1/html/ses-all/cha-ceph-iscsi.html
# https://daegonk.medium.com/ceph-iscsi-interface-38ce1889f5e1
# https://docs.ceph.com/en/quincy/rbd/iscsi-target-cli/

# wget https://download.ceph.com/ceph-iscsi/latest/rpm/el9/noarch/ceph-iscsi-3.7-1.el9.noarch.rpm
# wget https://download.ceph.com/ceph-iscsi/latest/rpm/el9/noarch/ceph-iscsi-tools-2.2-1.el9.noarch.rpm
# https://cbs.centos.org/koji/buildinfo?buildID=34736

# ceph-iscsi-3.7-1.el9.noarch.rpm
# tcmu-runner-1.5.4-4.el9s.x86_64.rpm
# libtcmu-1.5.4-4.el9s.x86_64.rpm
# libtcmu-devel-1.5.4-4.el9s.x86_64.rpm
# yum localinstall -y ceph-iscsi-3.7*.rpm tcmu-runner-1.5.4-4.el9s.x86_64.rpm libtcmu*.rpm


- name: List hosts for iSCSI Gateway
  shell: |
    ceph orch host ls
  register: hosts_listed
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ hosts_listed }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']


# ceph tell osd.* config get osd_heartbeat_grace
# ceph tell osd.* config get osd_heartbeat_interval
# ceph tell osd.* config get osd_client_watch_timeout

# To avoid initiator timeouts, three configuration parameters are suggested to be updated: osd heartbeat grace/interval and client watch timeout.
# The suggested values are 20, 5 and 15, respectively.
- name: Avoid initiator timeout
  shell: |
    ceph config set osd osd_heartbeat_grace 20
    ceph config set osd osd_heartbeat_interval 5
    ceph config set osd osd_client_watch_timeout 15
  register: initiator_timeout_avoided
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ initiator_timeout_avoided }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']


# Please note that replicated_rule is the default crush map when a Ceph Cluster is deployed
- name: Create a Replicated Pool with replicated_rule Crush Map
  shell: |
    ceph osd pool create {{ item.pg_name }} {{ item.pg_num }} {{ item.pgp_num }} {{ item.replica }}
  register: replica_pool_created
  with_items: "{{ iscsi.targets }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ replica_pool_created }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
  # replicated


- name: Initialize the Pool for RBD Application
  shell: |
    rbd pool init {{ item.pg_name }}
  register: rbd_pool_inited
  with_items: "{{ iscsi.targets }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ rbd_pool_inited }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']


- name:  Deploy iSCSI Gateway
  shell: |
    ceph orch apply iscsi {{ item.pg_name }} admin admin --placement='{{ ceph.mon_host_num }} {{ all_mon_hostnames }}' --trusted_ip_list='{{ item.trusted_ips }}'
  register: iscsi_gw_deployed
  with_items: "{{ iscsi.targets }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ iscsi_gw_deployed }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']

# ceph orch ls --service_type=iscsi
# ceph orch ps --daemon_type=iscsi
# firewall-cmd --permnent --add-port={5000/tcp,3260/tcp} --zone=public && firewall-cmd --reload
# podman ps # iscsi - tcmu
# gwcli ls


- pause:
    seconds: 30


- name: Get iSCSI Gateway Container ID
  shell: |
    podman ps | grep ceph | grep tcmu | awk '{print" "$NF}' | tr -d "^[:blank:]"
  register: iscsi_gw_cont_id
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ iscsi_gw_cont_id }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']


- name: Set command line for Podman iSCSI Gateway Container
  set_fact:
    podman_iscsi_gw_cmd: "podman exec -it {{ iscsi_gw_cont_id.stdout }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']


- name: Create iSCSI Target
  shell: |
    cat << EOF | {{ podman_iscsi_gw_cmd }} gwcli
    cd /iscsi-targets
    create {{ item.wwn }}
    exit
    EOF
  register: iscsi_target_created
  ignore_errors: true
  with_items: "{{ iscsi.targets }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ iscsi_target_created }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']


- name: Create iSCSI Gateways
  shell: |
    cat << EOF | {{ podman_iscsi_gw_cmd }} gwcli
    cd /iscsi-targets/{{ item.wwn }}/gateways
    create rk9-node01.jtest.weka.io 192.168.0.71
    create rk9-node02.jtest.weka.io 192.168.0.72
    create rk9-node03.jtest.weka.io 192.168.0.73
    exit
    EOF
  register: iscsi_target_created
  with_items: "{{ iscsi.targets }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ iscsi_target_created }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
# cd iqn.2024-04.io.weka.jtest.iscsi-gw:iscsi-igw
# ls
# cd gateways
# create rk9-node01.jtest.weka.io 192.168.0.71
# create rk9-node02.jtest.weka.io 192.168.0.72
# create rk9-node03.jtest.weka.io 192.168.0.73


- name: Create Pool and Images
  shell: |
    cat << EOF | {{ podman_iscsi_gw_cmd }} gwcli
    cd /disks
    create pool={{ item.pg_name }} image={{ item.image }} size={{ item.image_size }}
    exit
    EOF
  register: pool_image_created
  with_items: "{{ iscsi.targets }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ pool_image_created }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']

# cd iscsi-targets/iqn.2024-04.io.weka.jtest.iscsi-gw:iscsi-igw
# cd hosts
# create iqn.2024-04.io.weka.jtest:iscsi-client1
- name: Create iSCSI Initiator
  shell: |
    cat << EOF | {{ podman_iscsi_gw_cmd }} gwcli
    cd /iscsi-targets/{{ item.mutual_id }}/hosts
    create {{ item.wwn }}
    exit
    EOF
  register: iscsi_initiator_created
  with_items: "{{ iscsi.initiators }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ iscsi_initiator_created }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']


- name: Setup User and Password for iSCSI Initiators
  shell: |
    cat << EOF | {{ podman_iscsi_gw_cmd }} gwcli
    cd /iscsi-targets/{{ item.mutual_id }}/hosts
    auth username={{ item.auth_id }} password={{ item.password }}
    exit
    EOF
  register: user_password_setup
  with_items: "{{ iscsi.initiators }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ user_password_setup }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']


- name: Add Disk
  shell: |
    cat << EOF | {{ podman_iscsi_gw_cmd }} gwcli
    cd /iscsi-targets/{{ item.wwn }}/hosts
    disk add {{ item.pg_name }}/{{ item.image }}
    exit
    EOF
  register: disk_added
  with_items: "{{ iscsi.targets }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ disk_added }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']


# https://github.com/ceph/ceph-ansible/issues/3870
# ceph-ansible installs ceph-iscsi and tcmu-runner, but the initial configuration is broken (see my comments above, python errors while installing). When I manually configure gwcli (target, target IPs), ceph-ansible runs flawlessly afterwards. I try to track down the problem:
# Remove manually the gwcli-configuration
# on both iscsi-gateways: yum remove tcmu-runner ceph-iscsi

# gwcli / export copy | jq -r '.["version"]'
# https://stackoverflow.com/questions/71973210/gwcli-not-working-after-deleting-pool-in-ceph

