- name: Set Ceph FSID
  import_tasks: set-fsid.yml


- name: Get All OSD IDs
  shell: |
    ceph osd status | sed 1d | awk '{print $1}' | sort -nr | tr '\n' ',' | sed 's/,$/\n/'
  register: all_osd_ids
- debug: msg={{ all_osd_ids }}
  when: print_debug == true
  # ceph config dump | grep -E '^osd\.' | grep iops_ssd | awk '{print $1}' | cut -d . -f 2 | sort -nr | tr '\n' ',' | sed 's/,$/\n/'
  # ceph osd status | grep -E '{{ all_osd_nodes }}' | sed 1d | awk '{print $1}' | sort -nr | tr '\n' ',' | sed 's/,$/\n/'


- set_fact:
    all_osd: "{{ all_osd_ids.stdout | split(',')}}"
- debug: msg={{ item }}
  with_items: "{{ all_osd }}"
  when: print_debug == true


- name: Unlabel the OSD Nodes with Its Role
  shell: |
    ceph orch host label rm {{ hostvars[item]['ansible_hostname'] }} {{ hostvars[item]['ansible_hostname'] }}-osd
  register: unlabel_osd_nodes
  ignore_errors: true
  loop: "{{ groups['osd'] }}"
- debug: msg={{ unlabel_osd_nodes }}
  when: print_debug == true
  #  {{ cephadm_cmd }} ceph orch host label rm {{ hostvars[item]['ansible_hostname'] }} {{ hostvars[item]['ansible_hostname'] }}-osd


- name: Disable Scrub for OSDs
  shell: |
    {{ cephadm_cmd }} ceph tell osd.* injectargs --osd-max-backfills 1 --osd-recovery-max-active 1 --osd-recovery-op-priority 1
    {{ cephadm_cmd }} ceph osd set noscrub
    {{ cephadm_cmd }} ceph osd set nodeep-scrub
  register: disable_scrub
  ignore_errors: true
- debug: msg={{ disable_scrub }}
  when: print_debug == true
  # ceph tell osd.* injectargs --osd-max-backfills 1 --osd-recovery-max-active 1 --osd-recovery-op-priority 1


- name: Out OSDs
  shell: |
    {{ cephadm_cmd }} ceph osd out all
  register: osd_out
  ignore_errors: true
- debug: msg={{ osd_out }}
  when: print_debug == true
  # {{ cephadm_cmd }} ceph osd out {{ item }}
  # with_items: "{{ all_osd }}"


- name: Down OSDs
  shell: |
    {{ cephadm_cmd }} ceph osd down all
  register: down_osd
  ignore_errors: true
- debug: msg={{ down_osd }}
  when: print_debug == true
  # {{ cephadm_cmd }} ceph osd down {{ item }} --definitely-dead
  # with_items: "{{ all_osd }}"


- name: Remove OSDs
  shell: |
    {{ cephadm_cmd }} ceph osd rm {{ item }}
  register: remove_osd
  ignore_errors: true
  loop: "{{ all_osd }}"
- debug: msg={{ remove_osd }}
  when: print_debug == true


- name: Remove Auth of OSDs
  shell: |
    {{ cephadm_cmd }} ceph auth del osd.{{ item }}
  register: remove_osd_auth
  ignore_errors: true
  loop: "{{ all_osd }}"
- debug: msg={{ remove_osd_auth }}
  when: print_debug == true


- name:  Destroy OSDs
  shell: |
    {{ cephadm_cmd }} ceph osd destroy {{ item }} --force
  register: destroy_osd
  ignore_errors: true
  loop: "{{ all_osd }}"
- debug: msg={{ destroy_osd }}
  when: print_debug == true


- name: Remove Crush OSDs
  shell: |
    {{ cephadm_cmd }} ceph osd crush rm osd.{{ item }}
  register: remove_osd
  ignore_errors: true
  loop: "{{ all_osd }}"
- debug: msg={{ remove_osd }}
  when: print_debug == true


- name: Purge OSDs
  shell: |
    {{ cephadm_cmd }} ceph osd purge {{ item }} --force
  register: purge_osd
  ignore_errors: true
  loop: "{{ all_osd }}"
- debug: msg={{ purge_osd }}
  when: print_debug == true
  # {{ cephadm_cmd }} ceph osd purge {{ item }} --yes-i-really-mean-it


- name: Remove Host Bucket in Crush Map
  shell: |
    {{ cephadm_cmd }} ceph osd crush rm {{ item }}
  register: remove_bucket
  loop: "{{ groups['osd'] }}"
- debug: msg={{ remove_bucket }}
  when: print_debug == true


- name: Unset Scrub for OSDs
  shell: |
    {{ cephadm_cmd }} ceph tell osd.* injectargs --osd-max-backfills 1 --osd-recovery-max-active 3 --osd-recovery-op-priority 3
    {{ cephadm_cmd }} ceph osd unset noscrub
    {{ cephadm_cmd }} ceph osd unset nodeep-scrub
    {{ cephadm_cmd }} ceph osd unset noup
  register: unset_scrub
  ignore_errors: true
- debug: msg={{ unset_scrub }}
  when: print_debug == true


# https://access.redhat.com/documentation/ko-kr/red_hat_ceph_storage/1.2.3/html/red_hat_ceph_administration_guide/removing-osds-manual
- name: Delete OSD Users
  shell: |
    {{ cephadm_cmd }} ceph auth del client.ceph-exporter.{{ hostvars[item]['ansible_hostname'] }}
    {{ cephadm_cmd }} ceph auth del client.crash.{{ hostvars[item]['ansible_hostname'] }}
  register: delete_osd_users
  ignore_errors: true
  loop: "{{ groups['osd'] }}"
- debug: msg={{ delete_osd_users }}
  when: print_debug == true
  # ceph orch start node-exporter.rk9-node04
  # ceph orch redeploy node-exporter.rk9-node04
  # ceph orch redeploy node-exporter
  # ceph orch daemon restart node-exporter.rk9-node06
  # ceph orch daemon restart ceph-exporter.rk9-node05
  # ceph orch daemon restart crash.rk9-node06


# https://access.redhat.com/documentation/ko-kr/red_hat_ceph_storage/1.2.3/html/red_hat_ceph_administration_guide/removing-osds-manual
- name: Remove the Cluster Hosts and Check if There is Ceph Daemon Running
  shell: |
    ceph orch host rm {{ hostvars[item]['ansible_hostname'] }}
    ceph orch host drain {{ hostvars[item]['ansible_hostname'] }}
    ceph orch host rm --force {{ hostvars[item]['ansible_hostname'] }}
    ceph orch ps {{ hostvars[item]['ansible_hostname'] }}
  register: remove_cluster_hosts
  loop: "{{ groups['osd'] }}"
- debug: msg={{ remove_cluster_hosts }}
  when: print_debug == true
  # {{ cephadm_cmd }} ceph orch host ls
  #    {{ cephadm_cmd }} ceph orch host rm {{ hostvars[item]['ansible_hostname'] }}
  #  {{ cephadm_cmd }} ceph orch host drain {{ hostvars[item]['ansible_hostname'] }}
  #  {{ cephadm_cmd }} ceph orch host rm --force {{ hostvars[item]['ansible_hostname'] }}
  #  {{ cephadm_cmd }} ceph orch ps {{ hostvars[item]['ansible_hostname'] }}


#- name: Stop and Remove Ceph and Node Exporters's Containers
#  shell: |
#    for i in `systemctl list-units '*ceph*' | grep running | awk '{print $1}'`; do systemctl stop $i && systemctl disable $i ; done
#  ignore_errors: true
#  register: stop_exporter_containers
#  delegate_to: "{{ item }}"
#  delegate_facts: True
#  loop: "{{ groups['osd'] }}"
#- debug: msg={{ stop_exporter_containers }}
#  when: print_debug == true

# https://access.redhat.com/documentation/ko-kr/red_hat_ceph_storage/4/html/operations_guide/removing-a-ceph-osd-node_ops
# https://www.ibm.com/docs/en/storage-ceph/5?topic=failure-removing-ceph-osd-node
# podman images | awk '{print $3}'
# podman rmi -f 1c40e0e88d74


# https://access.redhat.com/documentation/ko-kr/red_hat_ceph_storage/1.2.3/html/red_hat_ceph_administration_guide/removing-osds-manual
#- name: Delete OSD Users
#  shell: |
#    {{ cephadm_cmd }} ceph auth del client.ceph-exporter.{{ hostvars[item]['ansible_hostname'] }}
#    {{ cephadm_cmd }} ceph auth del client.crash.{{ hostvars[item]['ansible_hostname'] }}
#  register: delete_osd_users
#  ignore_errors: true
#  loop: "{{ groups['osd'] }}"
#- debug: msg={{ delete_osd_users }}
#  when: print_debug == true


#- name: Remove FSID Directory
#  file:
#    path: "/var/lib/ceph/{{ _fsid }}"
#    state: absent
#  register: remove_fsid_dir
#  ignore_errors: true
#  delegate_to: "{{ item }}"
#  delegate_facts: True
#  loop: "{{ groups['osd'] }}"
#- debug: msg={{ remove_fsid_dir }}
#  when: print_debug == true
#
# https://access.redhat.com/documentation/ko-kr/red_hat_ceph_storage/4/html/operations_guide/removing-a-ceph-osd-node_ops
# https://www.ibm.com/docs/en/storage-ceph/5?topic=failure-removing-ceph-osd-node

