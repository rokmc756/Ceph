#
# https://stackoverflow.com/questions/36328907/ansible-get-all-the-ip-addresses-of-a-group
- set_fact:
    all_nodes_hostname: "{{ groups['mon'] | map('extract', hostvars, ['ansible_hostname']) | join(',') }}"

- debug: msg={{ all_nodes_hostname }}

#
- name: Install Ceph Reef
  become: true
  become_user: root
  shell: |
    /root/cephadm install
  register: install_ceph

- debug: msg={{ install_ceph }}
  when: print_debug == true

#
- name: Initialize Ceph Cluster Monitor On Ceph Admin Node
  become: true
  become_user: root
  shell: |
    /root/cephadm bootstrap --mon-ip {{ hostvars[groups['mon'][0]]['ansible_eth0']['ipv4']['address'] }} --allow-overwrite
  register: init_ceph
  ignore_errors: true

- debug: msg={{ init_ceph }}
  when: print_debug == true

#
- name: Install ceph-common
  become: true
  become_user: root
  shell: |
    /root/cephadm install ceph-common
  register: install_ceph_common
  ignore_errors: true

- debug: msg={{ install_ceph_common }}
  when: print_debug == true

#
- name: Check created containers
  become: true
  become_user: root
  shell: |
    podman ps
  register: check_containers

- debug: msg={{ check_containers }}
  when: print_debug == true

#
- name: List the containers if using podman
  become: true
  become_user: root
  shell: |
    podman ps
  register: list_podman

- debug: msg={{ list_podman }}
  when: print_debug == true

#
- name: List the containers if using podman
  become: true
  become_user: root
  shell: |
    systemctl list-units 'ceph*'
  register: list_containers

- debug: msg={{ list_containers }}
  when: print_debug == true

#
- name: Get fsid for setting fact
  become: true
  become_user: root
  shell: |
    /root/cephadm ls | grep fsid | uniq | awk '{print $2}' | sed -e "s/\"//g" | cut -d , -f 1
  register: get_fsid

- debug: msg={{ get_fsid.stdout }}
  when: print_debug == true

#
- name: Set fact for fsid
  set_fact:
    fsid01: "{{ get_fsid.stdout }}"

#
- name: Set fact for cephadm_cmd command
  set_fact:
    cephadm_cmd: "/usr/sbin/cephadm shell --fsid {{ fsid01 }} -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring --"

#
#- name: Enable Ceph CLI
#  become: true
#  become_user: root
#  shell: |
#    {{ cephadm_cmd }} ceph -s
#  register: enable_ceph_cli
#
#- debug: msg={{ enable_ceph_cli }}
#  when: print_debug == true

#
- name: Copy SSH Keys to Other Ceph Nodes
  shell: |
    ssh-copy-id -f -i /etc/ceph/ceph.pub root@{{ hostvars[item]['ansible_hostname'] }}
  register: copy_ssh_keys
  with_items: "{{ groups['all'] }}"

#
# {{ cephadm_cmd }} ceph orch host add {{ hostvars[item]['ansible_hostname'] }}
# {{ cephadm_cmd }} ceph orch host add {{ hostvars[groups['mon'][2]]['ansible_hostname'] }}
- name: Allow deployment of monitor daemons on arbitrary hosts to add the nodes to the cluster
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch host add {{ hostvars[item]['ansible_hostname'] }}
  register: add_nodes
  with_items: "{{ groups['mon'] }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']

- debug: msg={{ add_nodes }}
  when: print_debug == true

#
- name: Label the nodes with its role
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch host label add {{ hostvars[item]['ansible_hostname'] }} {{ hostvars[item]['ansible_hostname'] }}-mon
  register: label_nodes
  with_items: "{{ groups['mon'] }}"

- debug: msg={{ label_nodes }}
  when: print_debug == true

#
- name:  Confirm the labelling
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch host ls
  register: confirm_label

- debug: msg={{ confirm_label }}
  when: print_debug == true

#
#- name: Manually add monitors and disable automated monitor deployment
#  become: true
#  become_user: root
#  shell: |
#    {{ cephadm_cmd }} ceph orch apply mon --unmanaged
#  register: add_monitors
#
#- debug: msg={{ add_monitors }}
#  when: print_debug == true

# Ceph Monitor 데몬은 클러스터 구성원 자격, 구성 및 상태에 대한 매우 안정적이고 지속적인 저장을 제공하기 위하여 모든 노드에 MON 역할을 부여합니다.
# 역시 모든 노드에 MON 역할을 부여합니다.
- name: Apply the role of monitor for all nodes
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch apply mon --placement={{ all_nodes_hostname }}
  register: apply_monitors

- debug: msg={{ apply_monitors }}
  when: print_debug == true

# Ceph Manager 데몬은 모니터 데몬과 함께 실행되어 외부 모니터링 및 관리 시스템에 추가적인 모니터링 및 인터페이스를 제공합니다.
# 역시 모든 노드에 MGR 역할을 부여합니다.
- name: Apply the role of mgr for all nodes
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch apply mgr --placement={{ all_nodes_hostname }}
  register: apply_mgr

- debug: msg={{ apply_mgr }}
  when: print_debug == true

# CephRBD 뿐 아니라 CephFS 도 사용하기 위해 MDS 를 생성합니다. 미리 모든 노드에 MDS 역할을 부여 합니다.
# 여기에서는 파일시스템을 식별하기 위해 myfs 라는 이름으로 생성 하였습니다.
- name: Apply the role of mds for all nodes
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch apply mds myfs --placement={{ all_nodes_hostname }}
  register: apply_mds

- debug: msg={{ apply_mds }}
  when: print_debug == true

#
- name: Label the nodes with its role
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch host label add {{ hostvars[item]['ansible_hostname'] }} {{ hostvars[item]['ansible_hostname'] }}-mgr
  register: label_mgr
  with_items: "{{ groups['mon'] }}"

- debug: msg={{ label_mgr }}
  when: print_debug == true


#
- name:  Confirm the labelling
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch host ls
  register: confirm_label

- debug: msg={{ confirm_label }}
  when: print_debug == true



#
#- name: Deploy each additional monitor:
#  become: true
#  become_user: root
#  shell: |
#    {{ cephadm_cmd }} ceph orch daemon add mon *<host1:ip>
#  register: deploy_additional_monitor
#
#- debug: msg={{ deploy_additional_monitor }}

#
- name: Add the OSD Nodes to the cluster
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch host add {{ hostvars[item]['ansible_hostname'] }}
  register: add_osd_nodes
  with_items: "{{ groups['osd'] }}"

- debug: msg={{ add_osd_nodes }}
  when: print_debug == true
  #  {{ cephadm_cmd }} ceph orch host add {{ hostvars[item]['ansible_hostname'] }}:/dev/vdb
  #  {{ cephadm_cmd }} ceph orch host add {{ hostvars[item]['ansible_hostname'] }}:/dev/vdc
  #  {{ cephadm_cmd }} ceph orch host add {{ hostvars[item]['ansible_hostname'] }}:/dev/vdd

#
- name: Label the OSD nodes with its role
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch host label add {{ hostvars[item]['ansible_hostname'] }} {{ hostvars[item]['ansible_hostname'] }}-osd
  register: label_osd_nodes
  with_items: "{{ groups['osd'] }}"

- debug: msg={{ label_osd_nodes }}
  when: print_debug == true

#
- name: List Ceph Cluster Nodes
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch host ls
  register: list_ceph_nodes

- debug: msg={{ list_ceph_nodes }}
  when: print_debug == true

#
- name: List the devices that are available on the OSD nodes for creating OSDs using the command below;
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch device ls
  register: list_devices

- debug: msg={{ list_devices }}
  when: print_debug == true

#
- name: Attach all devices at once
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch apply osd --all-available-devices --method raw
  register: attach_all_devices
  # --method {raw|lvm}

- debug: msg={{ attach_all_devices }}
  when: print_debug == true

#
#- name: Disable the automatic creation of OSDs on available devices), use the 'unmanaged' parameter
#  become: true
#  become_user: root
#  shell: |
#    {{ cephadm_cmd }} ceph orch apply osd --all-available-devices --unmanaged=true
#  register: disable_auto_create_osds
#
#- debug: msg={{ disable_auto_create_osds }}
#  when: print_debug == true

#- name: Ceate manullay an OSD from a specific device on a specific host
#  become: true
#  become_user: root
#  shell: |
#    {{ cephadm_cmd }} ceph orch daemon add osd {{ hostvars[item]['ansible_hostname'] }}:/dev/vdb
#    {{ cephadm_cmd }} ceph orch daemon add osd {{ hostvars[item]['ansible_hostname'] }}:/dev/vdc
#    {{ cephadm_cmd }} ceph orch daemon add osd {{ hostvars[item]['ansible_hostname'] }}:/dev/vdd
#  register: create_osd_host
#  with_items: "{{ groups['osd'] }}"
#
#- debug: msg={{ create_osd_host }}
#  when: print_debug == true

#
- name: Check Ceph cluster health
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph -s
  register: check_ceph_health

- debug: msg={{ check_ceph_health }}
  when: print_debug == true

#
- name: Check OSDs
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph osd tree
  register: check_osd_tree

- debug: msg={{ check_osd_tree }}
  when: print_debug == true

#
- name: Get a list of Ceph services
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph orch ps
  register: check_ceph_services

- debug: msg={{ check_ceph_services }}
  when: print_debug == true

#
- name: Check created containers
  become: true
  become_user: root
  shell: |
    podman ps
  register: check_containers

- debug: msg={{ check_containers }}
  when: print_debug == true

#
- name: List the containers if using podman
  become: true
  become_user: root
  shell: |
    systemctl list-units 'ceph*'
  register: list_containers

- debug: msg={{ list_containers }}
  when: print_debug == true

#
- name: Activate the telemetry module
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} ceph telemetry on --license sharing-1-0
  register: activate_telemetry_module
  # ceph telemetry off

- debug: msg={{ activate_telemetry_module }}
  when: print_debug == true

#
- name: Change admin password for Ceph Dashboard
  become: true
  become_user: root
  shell: |
    {{ cephadm_cmd }} echo changeme > /tmp/dashboard_password.yml ; ceph dashboard ac-user-set-password admin -i /tmp/dashboard_password.yml
  register: change_admin_password
  # ceph telemetry off

- debug: msg={{ change_admin_password }}
  when: print_debug == true
