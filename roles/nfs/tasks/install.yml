#
- name: Get FSID
  shell: |
    cat /etc/ceph/ceph.conf | grep fsid | awk '{print $3}'
  register: get_fsid
- debug: msg={{ get_fsid.stdout }}
  when: print_debug == true

#
- name: Set Fact for FSID
  set_fact:
    _fsid: "{{ get_fsid.stdout }}"

#
- name: Set Fact for cephadm_cmd command
  set_fact:
    cephadm_cmd: "/usr/sbin/cephadm shell --fsid {{ _fsid }} -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring --"

#
- name: Create NFS
  shell: |
    ceph nfs cluster create {{ item.name }}
  register: create_nfs
  with_items: "{{ nfs.cluster }}"
- debug: msg={{ create_nfs }}
  when: print_debug == true

#
- name: Check the ls status when Creating NFS
  shell: |
    ceph orch ls --service_name=nfs.{{ item.name }}
  register: check_nfs_ls
  with_items: "{{ nfs.cluster }}"
- debug: msg={{ check_nfs_ls }}
  when: print_debug == true

#
- name: Check the ps status when Creating NFS
  shell: |
    ceph orch ps --service_name=nfs.{{ item.name }}
  register: check_nfs_ps
  with_items: "{{ nfs.cluster }}"
- debug: msg={{ check_nfs_ps }}
  when: print_debug == true

#
- name: Check the Cluster Info Status when Creating NFS
  shell: |
    ceph nfs cluster info {{ item.name }}
  register: check_nfs_clu_info
  with_items: "{{ nfs.cluster }}"
- debug: msg={{ check_nfs_clu_info }}
  when: print_debug == true

#
- name: Create a NFS filesystem Volume
  shell: |
    ceph fs volume create {{ item.fs }}
  register: create_nfs_vol
  with_items: "{{ nfs.cluster }}"
- debug: msg={{ create_nfs_vol }}
  when: print_debug == true

#
- name: Create a User, nfsclient to Expose CephFS though the NFS server
  shell: |
    ceph auth {{ item.action }} client.{{ item.user }} mon '{{ item.mon }}' \
    osd '{{ item.osd }} pool={{ item.pool }} namespace={{ item.namespace }}, {{ item.cephfs }} data={{ item.data }}' \
    mds '{{ item.mds }} path={{ item.path }}' > {{ item.key }}
  ignore_errors: true
  register: create_nfs_auth
  with_items: "{{ nfs.auth }}"
- debug: msg={{ create_nfs_auth }}
  when: print_debug == true

#
- name: Create a Configuration File and Apply it to the NFS Cluster
  shell: |
    ceph nfs cluster config set {{ item.name }} -i /root/nfs.conf
  ignore_errors: true
  register: create_nfs_config
  with_items: "{{ nfs.cluster }}"
- debug: msg={{ create_nfs_config }}
  when: print_debug == true

#
- name: Create a CephFS Export
  shell: |
    ceph nfs export create {{ item.name }} {{ item.cluster }} {{ item.src }} {{ item.fs }} --path={{ item.dest }}
  register: create_cephfs_export
  with_items: "{{ nfs.export }}"
- debug: msg={{ create_cephfs_export }}
  when: print_debug == true

#
- name: View the Export Block Based on the Pseudo Root Name
  shell: |
    ceph nfs export get {{ item.cluster }} {{ item.src }}
  register: view_nfs_export
  with_items: "{{ nfs.export }}"
- debug: msg={{ view_nfs_export }}
  when: print_debug == true

#
- name: List the NFS exports
  shell: |
    ceph nfs export ls {{ item.cluster }}
  register: list_nfs_export
  with_items: "{{ nfs.export }}"
- debug: msg={{ list_nfs_export }}
  when: print_debug == true

#
- name: Get the Information of the NFS Export
  shell: |
    ceph nfs cluster info {{ item.cluster }}
  register: get_nfs_export
  with_items: "{{ nfs.export }}"
- debug: msg={{ get_nfs_export }}
  when: print_debug == true

#
- name: Pause until Pools are started to Scrub
  pause:
    seconds: 40

#
- name: Check if Pools are still Unknown
  shell: |
    ceph pg stat
  register: unknown_pool_checked
  until: unknown_pool_checked.stdout.find("unknown") == -1
  retries: 30
  delay: 10
- debug: msg={{ unknown_pool_checked }}
  when: print_debug == true

#
- name: Check if Pools are Active+Clean
  shell: |
    ceph pg stat
  register: scrub_pool_checked
  until: scrub_pool_checked.stdout.find("scrubbing") == -1
  retries: 20
  delay: 15
- debug: msg={{ scrub_pool_checked }}
  when: print_debug == true

# ceph osd map cephfs.jtest-fs01.data jtest-ns01
# ceph health detail
# HEALTH_WARN 1 failed cephadm daemon(s)
