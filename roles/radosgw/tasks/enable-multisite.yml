# https://www.ibm.com/docs/en/storage-ceph/5?topic=gateway-deploying-multi-site-ceph-object
# [ Deploying a multi-site Ceph Object Gateway ]
# Ceph Orchestrator supports multi-site configuration options for the Ceph Object Gateway.
# You can configure each object gateway to work in an active-active zone configuration allowing writes to a non-primary zone.
# The multi-site configuration is stored within a container called a realm.
# The realm stores zone groups, zones, and a time period. The rgw daemons handle the synchronization eliminating the need for a separate synchronization agent,
# thereby operating with an active-active configuration. You can also deploy multi-site zones using the command line interface (CLI).
# NOTE: The following configuration assumes at least two IBM Storage Ceph clusters are in geographically separate locations.
# However, the configuration also works on the same site.

# Parent topic: Management of Ceph object gateway
# Prerequisites:
# - At least two running IBM Storage Ceph clusters.
# - At least two Ceph Object Gateway instances, one for each IBM Storage Ceph cluster.
# - Root-level access to all the nodes.
# - Nodes or containers are added to the storage cluster.
# - All Ceph Manager, Monitor and OSD daemons are deployed.

#
- name: Get FSID
  shell: |
    /root/cephadm ls | grep fsid | uniq | awk '{print $2}' | sed -e "s/\"//g" | cut -d , -f 1
  register: get_fsid
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
- debug: msg={{ get_fsid.stdout }}
  when: print_debug == true and inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']

#
- name: Set Fact for FSID
  set_fact:
    _fsid: "{{ get_fsid.stdout }}"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']

#
- name: Set Fact for cephadm command
  set_fact:
    cephadm_cmd: "/usr/sbin/cephadm shell --fsid {{ _fsid }} -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring --"
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']

#
- name: Create a Realm
  shell: |
   radosgw-admin realm create --rgw-realm=jtest.weka.io --default
  register: realm_created
  when: inventory_hostname in groups['rgw']
- debug: msg={{ realm_created }}
  when: print_debug == true and inventory_hostname in groups['rgw']

# radosgw-admin realm create --rgw-realm=jtest.weka.io --default
#{
#    "id": "13631a53-02b4-4a9d-9454-fb31d737ed95",
#    "name": "jtest.weka.io",
#    "current_period": "83084e50-cbf6-4c45-a9ef-b04a105e7b78",
#    "epoch": 1
#}

# If the storage cluster has a single realm, then specify the --default flag.
- name: Create a primary zone group
  shell: |
    radosgw-admin zonegroup create --rgw-zonegroup=us --endpoints=http://rk9-node01.jtest.weka.io:80 --master --default
  register: primary_zone_group_created
  when: inventory_hostname in groups['rgw']
- debug: msg={{ primary_zone_group_created }}
  when: print_debug == true and inventory_hostname in groups['rgw']

# Delete
# radosgw-admin zonegroup delete --zonegroup-id 116ade05-61a2-45e6-896e-114c442f7bfe


# radosgw-admin zonegroup create --rgw-zonegroup=us --endpoints=http://rgw.jtest.weka.io:80 --master --default
#{
#    "id": "116ade05-61a2-45e6-896e-114c442f7bfe",
#    "name": "us",
#    "api_name": "us",
#    "is_master": true,
#    "endpoints": [
#        "http://rgw.jtest.weka.io:80"
#    ],
#    "hostnames": [],
#    "hostnames_s3website": [],
#    "master_zone": "",
#    "zones": [],
#    "placement_targets": [
#        {
#            "name": "default-placement",
#            "tags": [],
#            "storage_classes": []
#        }
#    ],
#    "default_placement": "default-placement",
#    "realm_id": "13631a53-02b4-4a9d-9454-fb31d737ed95",
#    "sync_policy": {
#        "groups": []
#    },
#    "enabled_features": [
#        "resharding"
#    ]
#}

#
- name: Create a Primary Zone
  shell: |
    radosgw-admin zone create --rgw-zonegroup=us --rgw-zone=us-east-1 --endpoints=http://rk9-node01.jtest.weka.io:80 \
    --access-key=changeme --secret-key=changeme
  register: primary_zone_created
  when: inventory_hostname in groups['rgw']
- debug: msg={{ primary_zone_created }}
  when: print_debug == true and inventory_hostname in groups['rgw']

# radosgw-admin zone list
#{
#    "default_info": "90beb51e-7fcc-46c8-822c-aa03b8ba4053",
#    "zones": [
#        "us-east-1",
#        "default"
#    ]
#}
# radosgw-admin zone delete --zone-id 90beb51e-7fcc-46c8-822c-aa03b8ba4053


# radosgw-admin zone create --rgw-zonegroup=us --rgw-zone=us-east-1 --endpoints=http://rgw.jtest.weka.io:80 --access-key=changeme --secret-key=changeme
#2024-04-21T01:31:30.358+0900 7f6480f36880  0 NOTICE: promoted us-east-1 as new master_zone of zonegroup us
#{
#    "id": "90beb51e-7fcc-46c8-822c-aa03b8ba4053",
#    "name": "us-east-1",
#    "domain_root": "us-east-1.rgw.meta:root",
#    "control_pool": "us-east-1.rgw.control",
#    "gc_pool": "us-east-1.rgw.log:gc",
#    "lc_pool": "us-east-1.rgw.log:lc",
#    "log_pool": "us-east-1.rgw.log",
#    "intent_log_pool": "us-east-1.rgw.log:intent",
#    "usage_log_pool": "us-east-1.rgw.log:usage",
#    "roles_pool": "us-east-1.rgw.meta:roles",
#    "reshard_pool": "us-east-1.rgw.log:reshard",
#    "user_keys_pool": "us-east-1.rgw.meta:users.keys",
#    "user_email_pool": "us-east-1.rgw.meta:users.email",
#    "user_swift_pool": "us-east-1.rgw.meta:users.swift",
#    "user_uid_pool": "us-east-1.rgw.meta:users.uid",
#    "otp_pool": "us-east-1.rgw.otp",
#    "system_key": {
#        "access_key": "changeme",
#        "secret_key": "changeme"
#    },
#    "placement_pools": [
#        {
#            "key": "default-placement",
#            "val": {
#                "index_pool": "us-east-1.rgw.buckets.index",
#                "storage_classes": {
#                    "STANDARD": {
#                        "data_pool": "us-east-1.rgw.buckets.data"
#                    }
#                },
#                "data_extra_pool": "us-east-1.rgw.buckets.non-ec",
#                "index_type": 0,
#                "inline_data": true
#            }
#        }
#    ],
#    "realm_id": "13631a53-02b4-4a9d-9454-fb31d737ed95",
#    "notif_pool": "us-east-1.rgw.log:notif"
#}


# IMPORTANT: Do not delete the default zone and its pools if you are using the default zone and zone group to store data.
# Also, removing the default zone group deletes the system user.
- name: Delete the default zone and zone group ( Optional )
  shell: |
    radosgw-admin zonegroup delete --rgw-zonegroup=default
  register: default_zone_deleted
  when: inventory_hostname in groups['rgw']
- debug: msg={{ default_zone_deleted }}
  when: print_debug == true and inventory_hostname in groups['rgw']

#
- name: Delete the associated pools ( Optional )
  shell: |
    ceph osd pool rm {{ item }} {{ item }} --yes-i-really-really-mean-it
  register: pools_deleted
  with_items:
    - "default.rgw.log"
    - "default.rgw.meta"
    - "default.rgw.control"
    - "default.rgw.data.root"
    - "default.rgw.gc"
  when: inventory_hostname in groups['rgw']
- debug: msg={{ pools_deleted }}
  when: print_debug == true and inventory_hostname in groups['rgw']

# [root@rk9-node01 ~]# radosgw-admin zonegroup delete --rgw-zonegroup=default
# [root@rk9-node01 ~]# ceph osd pool rm default.rgw.log default.rgw.log --yes-i-really-really-mean-it
# Error EPERM: pool deletion is disabled; you must first set the mon_allow_pool_delete config option to true before you can destroy a pool

# ceph tell mon.\* injectargs '--mon-allow-pool-delete=true'
# mon.rk9-node01: {}
# mon.rk9-node01: mon_allow_pool_delete = 'true'
# mon.rk9-node02: {}
# mon.rk9-node02: mon_allow_pool_delete = 'true'
# mon.rk9-node03: {}
# mon.rk9-node03: mon_allow_pool_delete = 'true'
# ceph osd pool rm default.rgw.log default.rgw.log --yes-i-really-really-mean-it
# pool 'default.rgw.log' removed
# pool 'default.rgw.meta' removed
# ceph osd pool rm default.rgw.control default.rgw.control --yes-i-really-really-mean-it
# pool 'default.rgw.control' removed
# ceph osd pool rm default.rgw.data.root default.rgw.data.root --yes-i-really-really-mean-it
# pool 'default.rgw.data.root' does not exist
#  ceph osd pool rm default.rgw.gc default.rgw.gc --yes-i-really-really-mean-it
# pool 'default.rgw.gc' does not exist

#
- name: Create a system user
  shell: |
    radosgw-admin user create --uid=zone.user --display-name="Zone user" --system
  register: system_user_created
  when: inventory_hostname in groups['rgw']
- debug: msg={{ system_user_created }}
  when: print_debug == true and inventory_hostname in groups['rgw']

# radosgw-admin user rm --uid=zone.user --purge-data

# radosgw-admin user create --uid=zone.user --display-name="Zone user" --system
#2024-04-21T01:35:53.496+0900 7fcbf6930880  0 period (83084e50-cbf6-4c45-a9ef-b04a105e7b78 does not have zone 90beb51e-7fcc-46c8-822c-aa03b8ba4053 configured
#{
#    "user_id": "zone.user",
#    "display_name": "Zone user",
#    "email": "",
#    "suspended": 0,
#    "max_buckets": 1000,
#    "subusers": [],
#    "keys": [
#        {
#            "user": "zone.user",
#            "access_key": "DNU5O4C37VND0PUWDV9W",
#            "secret_key": "sMA3zUPEq6ieNqCOK0B6KlLDJqb83bEYl7YptRzQ"
#        }
#    ],
#    "swift_keys": [],
#    "caps": [],
#    "op_mask": "read, write, delete",
#    "system": true,
#    "default_placement": "",
#    "default_storage_class": "",
#    "placement_tags": [],
#    "bucket_quota": {
#        "enabled": false,
#        "check_on_raw": false,
#        "max_size": -1,
#        "max_size_kb": 0,
#        "max_objects": -1
#    },
#    "user_quota": {
#        "enabled": false,
#        "check_on_raw": false,
#        "max_size": -1,
#        "max_size_kb": 0,
#        "max_objects": -1
#    },
#    "temp_url_keys": [],
#    "type": "rgw",
#    "mfa_ids": []
#}

# Make a note of the access_key and secret_key.
- name: Add the access key and system key to the primary zone
  shell: |
    radosgw-admin zone modify --rgw-zone=us-east-1 --access-key=changeme --secret=changeme
  register: access_system_key_added
  when: inventory_hostname in groups['rgw']
- debug: msg={{ access_system_key_added }}
  when: print_debug == true and inventory_hostname in groups['rgw']

# radosgw-admin zone modify --rgw-zone=us-east-1 --access-key=changeme --secret=changeme
#{
#    "id": "90beb51e-7fcc-46c8-822c-aa03b8ba4053",
#    "name": "us-east-1",
#    "domain_root": "us-east-1.rgw.meta:root",
#    "control_pool": "us-east-1.rgw.control",
#    "gc_pool": "us-east-1.rgw.log:gc",
#    "lc_pool": "us-east-1.rgw.log:lc",
#    "log_pool": "us-east-1.rgw.log",
#    "intent_log_pool": "us-east-1.rgw.log:intent",
#    "usage_log_pool": "us-east-1.rgw.log:usage",
#    "roles_pool": "us-east-1.rgw.meta:roles",
#    "reshard_pool": "us-east-1.rgw.log:reshard",
#    "user_keys_pool": "us-east-1.rgw.meta:users.keys",
#    "user_email_pool": "us-east-1.rgw.meta:users.email",
#    "user_swift_pool": "us-east-1.rgw.meta:users.swift",
#    "user_uid_pool": "us-east-1.rgw.meta:users.uid",
#    "otp_pool": "us-east-1.rgw.otp",
#    "system_key": {
#        "access_key": "changeme",
#        "secret_key": "changeme"
#    },
#    "placement_pools": [
#        {
#            "key": "default-placement",
#            "val": {
#                "index_pool": "us-east-1.rgw.buckets.index",
#                "storage_classes": {
#                    "STANDARD": {
#                        "data_pool": "us-east-1.rgw.buckets.data"
#                    }
#                },
#                "data_extra_pool": "us-east-1.rgw.buckets.non-ec",
#                "index_type": 0,
#                "inline_data": true
#            }
#        }
#    ],
#    "realm_id": "13631a53-02b4-4a9d-9454-fb31d737ed95",
#    "notif_pool": "us-east-1.rgw.log:notif"
#}

#
- name: Commit the changes
  shell: |
    radosgw-admin period update --commit
  register: changes_commited
  when: inventory_hostname in groups['rgw']
- debug: msg={{ changes_commited }}
  when: print_debug == true and inventory_hostname in groups['rgw']

# radosgw-admin period update --commit
#2024-04-21T01:38:40.281+0900 7ff5e429d880  0 period (83084e50-cbf6-4c45-a9ef-b04a105e7b78 does not have zone 90beb51e-7fcc-46c8-822c-aa03b8ba4053 configured
#{
#    "id": "932e0e2b-2bbc-46e7-a5dc-311cf52c1fce",
#    "epoch": 1,
#    "predecessor_uuid": "83084e50-cbf6-4c45-a9ef-b04a105e7b78",
#    "sync_status": [],
#    "period_map": {
#        "id": "932e0e2b-2bbc-46e7-a5dc-311cf52c1fce",
#        "zonegroups": [
#            {
#                "id": "116ade05-61a2-45e6-896e-114c442f7bfe",
#                "name": "us",
#                "api_name": "us",
#                "is_master": true,
#                "endpoints": [
#                    "http://rgw.jtest.weka.io:80"
#                ],
#                "hostnames": [],
#                "hostnames_s3website": [],
#                "master_zone": "90beb51e-7fcc-46c8-822c-aa03b8ba4053",
#                "zones": [
#                    {
#                        "id": "90beb51e-7fcc-46c8-822c-aa03b8ba4053",
#                        "name": "us-east-1",
#                        "endpoints": [
#                            "http://rgw.jtest.weka.io:80"
#                        ],
#                        "log_meta": false,
#                        "log_data": false,
#                        "bucket_index_max_shards": 11,
#                        "read_only": false,
#                        "tier_type": "",
#                        "sync_from_all": true,
#                        "sync_from": [],
#                        "redirect_zone": "",
#                        "supported_features": [
#                            "compress-encrypted",
#                            "resharding"
#                        ]
#                    }
#                ],
#                "placement_targets": [
#                    {
#                        "name": "default-placement",
#                        "tags": [],
#                        "storage_classes": [
#                            "STANDARD"
#                        ]
#                    }
#                ],
#                "default_placement": "default-placement",
#                "realm_id": "13631a53-02b4-4a9d-9454-fb31d737ed95",
#                "sync_policy": {
#                    "groups": []
#                },
#                "enabled_features": [
#                    "resharding"
#                ]
#            }
#        ],
#        "short_zone_ids": [
#            {
#                "key": "90beb51e-7fcc-46c8-822c-aa03b8ba4053",
#                "val": 1089743150
#            }
#        ]
#    },
#    "master_zonegroup": "116ade05-61a2-45e6-896e-114c442f7bfe",
#    "master_zone": "90beb51e-7fcc-46c8-822c-aa03b8ba4053",
#    "period_config": {
#        "bucket_quota": {
#            "enabled": false,
#            "check_on_raw": false,
#            "max_size": -1,
#            "max_size_kb": 0,
#            "max_objects": -1
#        },
#        "user_quota": {
#            "enabled": false,
#            "check_on_raw": false,
#            "max_size": -1,
#            "max_size_kb": 0,
#            "max_objects": -1
#        },
#        "user_ratelimit": {
#            "max_read_ops": 0,
#            "max_write_ops": 0,
#            "max_read_bytes": 0,
#            "max_write_bytes": 0,
#            "enabled": false
#        },
#        "bucket_ratelimit": {
#            "max_read_ops": 0,
#            "max_write_ops": 0,
#            "max_read_bytes": 0,
#            "max_write_bytes": 0,
#            "enabled": false
#        },
#        "anonymous_ratelimit": {
#            "max_read_ops": 0,
#            "max_write_ops": 0,
#            "max_read_bytes": 0,
#            "max_write_bytes": 0,
#            "enabled": false
#        }
#    },
#    "realm_id": "13631a53-02b4-4a9d-9454-fb31d737ed95",
#    "realm_name": "jtest.weka.io",
#    "realm_epoch": 2
#}


#
# ??? Need copy client.admin.keyring to keyring in /var/lib/ceph/radosgw/ceph-rgw.rk9-node01/ ???
# ceph auth get-or-create client.rgw.rk9-node01  osd 'allow rwx' mon 'allow rw' -o /var/lib/ceph/radosgw/ceph-rgw.rk9-node01/keyring


# Need to check how to find services
# Outside the cephadm shell, fetch the FSID of the storage cluster and the processes:
- name: Start the Ceph Object Gateway daemon
  shell: |
    systemctl start ceph-62a081a6-88aa-11eb-a367-001a4a000672@rgw.test_realm.us-east-1.host01.ahdtsw.service
    systemctl enable ceph-62a081a6-88aa-11eb-a367-001a4a000672@rgw.test_realm.us-east-1.host01.ahdtsw.service
  register: ceph_obj_gw_started
  when: inventory_hostname in groups['rgw']
- debug: msg={{ ceph_obj_gw_started }}
  when: print_debug == true and inventory_hostname in groups['rgw']


# Modified
# vi /etc/ceph/ceph.conf
#
# [client.rgw.rk9-node01]
# host = 192.168.0.71
# rgw frontends = "civetweb port=80"

# systemctl start ceph-radosgw@rgw.`hostname -s`
# systemctl enable ceph-radosgw@rgw.`hostname -s`
# Created symlink /etc/systemd/system/ceph-radosgw.target.wants/ceph-radosgw@rgw.rk9-node01.service → /usr/lib/systemd/system/ceph-radosgw@.service.

# Need to create Auth
#- name: Create Authentication for Rados Gateway
#  shell: |
#    ceph auth {{ item.action }} client.rgw.{{ hostvars[inventory_hostname]['ansible_hostname'] }} \
#    osd '{{ item.osd }}' mon '{{ item.mon }}' \
#    -o /var/lib/ceph/radosgw/ceph-rgw.{{ hostvars[inventory_hostname]['ansible_hostname'] }}/keyring
#  register: rgw_auth_created
#  with_items: "{{ rgw.auth }}"
#  when: inventory_hostname in groups['rgw']
#- debug: msg={{ rgw_auth_created }}
#  when: print_debug == true and inventory_hostname in groups['rgw']

# In the Cephadm shell, configure the secondary zone.
- name: Pull the primary realm configuration from the host
  shell: |
    radosgw-admin realm pull --url=http://10.74.249.26:80 --access-key=changeme --secret-key=changeme
  register: primary_realm_config_pull
  when: inventory_hostname in groups['rgw']
- debug: msg={{ primary_realm_config_pull }}
  when: print_debug == true and inventory_hostname in groups['rgw']

# radosgw-admin realm pull --url=http://192.168.0.72:80 --access-key=changeme --secret-key=changeme
# request failed: (5) Input/output error
# radosgw-admin realm pull --url=http://192.168.0.73:80 --access-key=changeme --secret-key=changeme
# request failed: (5) Input/output error
# radosgw-admin realm pull --url=http://192.168.0.71:80 --access-key=changeme --secret-key=changeme
# request failed: (5) Input/output error
# radosgw-admin realm pull --url=http://192.168.1.73:80 --access-key=changeme --secret-key=changeme
# request failed: (5) Input/output error

#
- name: Pull the primary period configuration from the host
  shell: |
    radosgw-admin period pull --url=http://10.74.249.26:80 --access-key=changeme --secret-key=changeme
  register: primary_period_config_pull
  when: inventory_hostname in groups['rgw']
- debug: msg={{ primary_period_config_pull }}
  when: print_debug == true and inventory_hostname in groups['rgw']

#
- name: Configure a Secondary Zone
  shell: |
    radosgw-admin zone create --rgw-zonegroup=us --rgw-zone=us-east-2 --endpoints=http://rgw2:80 --access-key=changeme \
    --secret-key=changeme --endpoints=http://rgw.example.com:80
  register: secondary_zone_configured
  when: inventory_hostname in groups['rgw']
- debug: msg={{ secondary_zone_configured }}
  when: print_debug == true and inventory_hostname in groups['rgw']

# IMPORTANT: Do not delete the default zone and its pools if you are using the default zone and zone group to store data.
# To access old data in the default zone and zonegroup, use --rgw-zone default and --rgw-zonegroup default in radosgw-admin commands.
- name: Delete the default zone ( Optional )
  shell: |
    radosgw-admin zone rm --rgw-zone=default
  register: default_zone_deleted
  when: inventory_hostname in groups['rgw']
- debug: msg={{ default_zone_deleted }}
  when: inventory_hostname in groups['rgw']

#
- name: Delete pools for the default zone
  shell: |
    ceph osd pool rm {{ item }} {{ item }} --yes-i-really-really-mean-it
  register: pool_default_zone_deleted
  with_items:
    - "default.rgw.log"
    - "default.rgw.meta"
    - "default.rgw.control"
    - "default.rgw.data.root"
    - "default.rgw.gc"
  when: inventory_hostname in groups['rgw']
- debug: msg={{ pool_default_zone_deleted }}
  when: print_debug == true and inventory_hostname in groups['rgw']

#
- name: Update the Ceph configuration database
  shell: |
    ceph config set rgw rgw_zone us-east-2
  register: ceph_config_db_updated
  when: inventory_hostname in groups['rgw']
- debug: msg={{ ceph_config_db_updated }}
  when: print_debug == true and inventory_hostname in groups['rgw']

#
- name: Commit the changes
  shell: |
    radosgw-admin period update --commit
  register: changes_commited
  when: inventory_hostname in groups['rgw']
- debug: msg={{ changes_commited }}
  when: print_debug == true and inventory_hostname in groups['rgw']

#
- name: Fetch the FSID of the storage cluster and the processes outside the Cephadm shell
  shell: |
    systemctl list-units | grep ceph
  register: storage_cluster_fsid_fetched
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
  when: inventory_hostname in groups['rgw']
- debug: msg={{ storage_cluster_fsid_fetched }}
  when: print_debug == true and inventory_hostname in groups['rgw']

#
- name: Start the Ceph Object Gateway daemon
  shell: |
    systemctl start ceph-62a081a6-88aa-11eb-a367-001a4a000672@rgw.test_realm.us-east-2.host04.ahdtsw.service
    systemctl enable ceph-62a081a6-88aa-11eb-a367-001a4a000672@rgw.test_realm.us-east-2.host04.ahdtsw.service
  register: ceph_obj_gw_started
  when: inventory_hostname in groups['rgw']
- debug: msg={{ ceph_obj_gw_started }}
  when: print_debug == true and inventory_hostname in groups['rgw']

# Optional: Deploy multi-site Ceph Object Gateways using the placement specification:
- name: Deploy multi-site Ceph Object Gateways using the placement specification ( Optional )
  shell: |
    ceph orch apply rgw east --realm=test_realm --zone=us-east-1 --placement="2 host01 host02"
  register: multi_site_ceph_obj_gw_deployed
  when: inventory_hostname in hostvars[groups['mon'][0]]['ansible_hostname']
  when: inventory_hostname in groups['rgw']
- debug: msg={{ multi_size_ceph_obj_gw_deployed }}
  when: print_debug == true and inventory_hostname in groups['rgw']


# Verification
- name: Check the synchronization status to verify the deployment
  shell: |
    radosgw-admin sync status
  register: sync_status_checked
  when: inventory_hostname in groups['rgw']
- debug: msg={{ sync_status_checked }}
  when: print_debug == true and inventory_hostname in groups['rgw']

